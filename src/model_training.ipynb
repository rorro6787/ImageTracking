{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-2AKjD2mYKH",
        "outputId": "2c5180cc-678e-46df-b96c-528c871afb26"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgkfFCrCmfLf",
        "outputId": "2108af37-8679-41b7-b715-8e1684bc8c64"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1a2jk-fmfNZ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import sys\n",
        "from ultralytics import YOLO\n",
        "import shutil\n",
        "import random\n",
        "from zipfile import ZipFile\n",
        "import gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YLQEdMrmfPc"
      },
      "outputs": [],
      "source": [
        "cd = os.getcwd()                    # it's gonna be /src\n",
        "base_path = 'dataset_split'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJJnxLVhmfRi"
      },
      "outputs": [],
      "source": [
        "def move_files(data, split, images_path, labels_path):\n",
        "    \"\"\"\n",
        "    Moves files to their respective directories based on the split.\n",
        "\n",
        "    Args:\n",
        "        data (list): List of tuples containing image and label filenames.\n",
        "        split (str): The type of split ('train', 'val', 'test').\n",
        "        images_path (str): Path to the directory containing images.\n",
        "        labels_path (str): Path to the directory containing labels.\n",
        "    \"\"\"\n",
        "\n",
        "    for img_file, lbl_file in data:\n",
        "        shutil.move(os.path.join(images_path, img_file), os.path.join(base_path, split, 'images', img_file))\n",
        "        shutil.move(os.path.join(labels_path, lbl_file), os.path.join(base_path, split, 'labels', lbl_file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfjvo3u0mqtQ"
      },
      "outputs": [],
      "source": [
        "def remove_empty_dirs(path):\n",
        "    \"\"\"\n",
        "    Removes empty directories including the base directory if it's empty.\n",
        "\n",
        "    Args:\n",
        "        path (str): Path to the base directory.\n",
        "    \"\"\"\n",
        "    for dirpath, dirnames, filenames in os.walk(path, topdown=False):\n",
        "        if not dirnames and not filenames:\n",
        "            os.rmdir(dirpath)\n",
        "\n",
        "    # Attempt to remove the base directory\n",
        "    try:\n",
        "        os.rmdir(path)\n",
        "    except OSError as e:\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdMkrW-ym4t8"
      },
      "outputs": [],
      "source": [
        "def removeAll():\n",
        "    if os.path.exists(f\"{cd}/dataset_split\"):\n",
        "        shutil.rmtree(f'{cd}/dataset_split', ignore_errors=True)\n",
        "        print(\"Data distribution deleted successfully ...\")\n",
        "    else:\n",
        "        print(f\"The directory {cd}/dataset_split does not exist.\")\n",
        "    if os.path.exists(f\"{cd}/dataset.zip\"):\n",
        "        os.remove(f\"{cd}/dataset.zip\")\n",
        "        print(\"dataset.zip deleted successfully ...\")\n",
        "    else:\n",
        "        print(f\"The file {cd}/dataset_zip does not exist.\")\n",
        "    if os.path.exists(f\"{cd}/dataset\"):\n",
        "        shutil.rmtree(f'{cd}/dataset', ignore_errors=True)\n",
        "        print(\"Data distribution deleted successfully ...\")\n",
        "    else:\n",
        "        print(f\"The directory {cd}/dataset does not exist.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDqKgY1am_xr"
      },
      "outputs": [],
      "source": [
        "def prepare_structure():\n",
        "    \"\"\"\n",
        "    Prepares the directory structure for the rock_paper_scissors dataset and splits the data into training, validation, and test sets.\n",
        "\n",
        "    Unzips the dataset, shuffles the data, splits it into training (60%), validation (30%), and test (10%) sets,\n",
        "    and moves the files into the corresponding directories.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define paths\n",
        "    zip_file_path = 'dataset.zip'\n",
        "    base_extract_path = 'dataset'\n",
        "    url = 'https://drive.google.com/uc?id=1h7PrvmW8SaI6wyGE1x2bD-nMirccyfcr'\n",
        "    gdown.download(url,zip_file_path,quiet=False)\n",
        "\n",
        "    # Unzip the file\n",
        "    with ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(base_extract_path)\n",
        "\n",
        "    # Paths for extracted images and labels\n",
        "    images_path = os.path.join(base_extract_path, 'all_images')\n",
        "    labels_path = os.path.join(base_extract_path, 'all_labels')\n",
        "\n",
        "    # Gather image and label file names and sort them in ascending order (in this case string order)\n",
        "    image_files = sorted(os.listdir(images_path))\n",
        "    label_files = sorted(os.listdir(labels_path))\n",
        "    assert len(image_files) == len(label_files) == 6759 # (alredy known number of items in dataset)\n",
        "\n",
        "    # Shuffle and split data. Data is a list of tuples ...\n",
        "    data = list(zip(image_files, label_files))\n",
        "    random.shuffle(data)\n",
        "\n",
        "    train_data = data[:int(0.6 * len(data))]\n",
        "    val_data = data[int(0.6 * len(data)):int(0.9 * len(data))]\n",
        "    test_data = data[int(0.9 * len(data)):]\n",
        "\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        os.makedirs(os.path.join(base_path, split, 'images'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(base_path, split, 'labels'), exist_ok=True)\n",
        "\n",
        "    move_files(train_data,'train',images_path,labels_path)\n",
        "    move_files(val_data,'val',images_path,labels_path)\n",
        "    move_files(test_data,'test',images_path,labels_path)\n",
        "\n",
        "    # Remove empty directories\n",
        "    remove_empty_dirs(base_extract_path)\n",
        "\n",
        "    # Create config.yaml file\n",
        "    config_content = f\"\"\"path: {os.path.join(cd, 'dataset_split')}\\ntrain: train\\nval: val\\ntest: test\\n\\nnc: 3\\nnames: ['paper', 'rock', 'scissors']\"\"\"\n",
        "\n",
        "    with open(os.path.join(base_path, 'config.yaml'), 'w') as file:\n",
        "        file.write(config_content)\n",
        "\n",
        "    print(\"Data distribution and yaml creation completed successfully ...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LD4xU0enGi6"
      },
      "outputs": [],
      "source": [
        "def train_model(yaml_file, epochs, project):\n",
        "    \"\"\"\n",
        "    Trains the YOLO model on the provided dataset and saves the training metrics.\n",
        "\n",
        "    Args:\n",
        "        yaml_file (str): Path to the YOLO configuration YAML file.\n",
        "        epochs (int): Number of training epochs.\n",
        "        project (str): Path to the project directory where the training results will be saved.\n",
        "    \"\"\"\n",
        "\n",
        "    model = YOLO(model=\"yolov8n.pt\", task=\"detect\")\n",
        "    model.to('cuda')\n",
        "    model.train(data = yaml_file,\n",
        "        \t  epochs = epochs,\n",
        "              project = project,\n",
        "        \t  batch = 8,\n",
        "              name = \"train\")          # batch = 8 is neccesary because GPU does not support higher\n",
        "\n",
        "    results2 = model.val(data = yaml_file,\n",
        "                        project = project,\n",
        "                        batch = 8,\n",
        "                        name = \"test\",\n",
        "                        split = \"test\")\n",
        "\n",
        "    # Crear la ruta completa para el archivo de texto\n",
        "    metrics_file_path2 = os.path.join(project, \"testing_metrics.txt\")\n",
        "\n",
        "    # Escribir las métricas en el archivo de texto\n",
        "    with open(metrics_file_path2, 'w') as f:\n",
        "        f.write(\"Another metrics:\\n\")\n",
        "        f.write(\" Average precision for all classes: {}\\n\".format(results2.box.all_ap))\n",
        "        f.write(\" Average precision: {}\\n\".format(results2.box.ap))\n",
        "        f.write(\" Average precision at IoU=0.50: {}\\n\".format(results2.box.ap50))\n",
        "        f.write(\" F1 score: {}\\n\".format(results2.box.f1))\n",
        "        f.write(\" Mean average precision: {}\\n\".format(results2.box.map))\n",
        "        f.write(\" Mean average precision at IoU=0.50: {}\\n\".format(results2.box.map50))\n",
        "        f.write(\" Mean average precision at IoU=0.75: {}\\n\".format(results2.box.map75))\n",
        "        f.write(\" Mean average precision for different IoU thresholds: {}\\n\".format(results2.box.maps))\n",
        "        f.write(\" Mean precision: {}\\n\".format(results2.box.mp))\n",
        "        f.write(\" Mean recall: {}\\n\".format(results2.box.mr))\n",
        "        f.write(\" Precision: {}\\n\".format(results2.box.p))\n",
        "        f.write(\" Precision values: {}\\n\".format(results2.box.prec_values))\n",
        "        f.write(\" Recall: {}\\n\".format(results2.box.r))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TMtxA3cnIGH",
        "outputId": "162d3aef-f0dd-4a90-ad07-ad0f9b82077d"
      },
      "outputs": [],
      "source": [
        "prepare_structure()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZyouMtBnKoe",
        "outputId": "0ecbd7de-329f-4a84-a0c0-28fbe7a60f74"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtkn8arZnQr7",
        "outputId": "d75f4e87-86e5-46a4-f527-264913dbdeab"
      },
      "outputs": [],
      "source": [
        "train_model(f\"{cd}/dataset_split/config.yaml\",32,\"Hands_Tracking_Model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mD9K1koonfhr"
      },
      "outputs": [],
      "source": [
        "!yolo detect predict save model=\"/content/Hands_Tracking_Model/train/weights/best.pt\" source='/content/sn-rockpaper.png'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJdi7TW1rMud"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "import shutil\n",
        "# Ruta a la carpeta en el entorno de Colab\n",
        "folder_path = '/content/Hands_Tracking_Model'  # Cambia esto por la ruta correcta\n",
        "# Ruta al archivo ZIP que se creará\n",
        "zip_path = '/content/Hands_Tracking_Model.zip'\n",
        "# Comprimir la carpeta\n",
        "shutil.make_archive('/content/Hands_Tracking_Model', 'zip', folder_path)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(zip_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
